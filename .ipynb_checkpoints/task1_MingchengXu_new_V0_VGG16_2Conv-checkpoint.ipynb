{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1d234e3f-af8b-4757-83f3-241b04b7a511"
    }
   },
   "source": [
    "# Class Challenge: Image Classification of COVID-19 X-rays\n",
    "# Task 1 [Total points: 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b07b9992-b592-4871-9f9a-3b0ae5fa8b5f"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "* This assignment involves the following packages: 'matplotlib', 'numpy', and 'sklearn'. \n",
    "\n",
    "* If you are using conda, use the following commands to install the above packages:<br>\n",
    "```shell\n",
    "conda install matplotlib\n",
    "conda install numpy\n",
    "conda install -c anaconda scikit-learn\n",
    "```\n",
    "\n",
    "* If you are using pip, use use the following commands to install the above packages: <br> \n",
    "```shell\n",
    "pip install matplotlib\n",
    "pip install numpy\n",
    "pip install sklearn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5516f610-f00c-43c3-bf19-4cf7ab9c089f"
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "Please download the data using the following link: [COVID-19](https://drive.google.com/file/d/1Y88tgqpQ1Pjko_7rntcPowOJs_QNOrJ-/view). \n",
    "\n",
    "* After downloading 'Covid_Data_GradientCrescent.zip', unzip the file and you should see the following data structure:\n",
    "\n",
    "\n",
    "|--all<br>\n",
    "|--------train<br>\n",
    "|--------test<br>\n",
    "|--two<br>\n",
    "|--------train<br>\n",
    "|--------test<br>\n",
    "\n",
    "\n",
    "* Put the 'all' folder, the 'two' folder and this python notebook in the **same directory** so that the following code can correctly locate the data.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "## [20 points] Binary Classification: COVID-19 vs. Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "5e05f980-3d14-4367-b3d1-664249145b13"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "58317664-8da3-4283-b3e5-35721687e7ab"
    }
   },
   "outputs": [],
   "source": [
    "DATA_LIST = os.listdir('two/train')\n",
    "DATASET_PATH  = 'two/train'\n",
    "TEST_DIR =  'two/test'\n",
    "IMAGE_SIZE    = (224, 224)\n",
    "NUM_CLASSES   = len(DATA_LIST)\n",
    "BATCH_SIZE    = 10  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
    "NUM_EPOCHS    = 40\n",
    "LEARNING_RATE = 0.001 # start off with high rate first 0.001 and experiment with reducing it gradually "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### Generate Training and Validation Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "71760e29-2b08-4259-93f1-ebe68cd74a6d"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:342: UserWarning: This ImageDataGenerator specifies `zca_whitening` which overrides setting of`featurewise_std_normalization`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 104 images belonging to 2 classes.\n",
      "Found 26 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=50,featurewise_center = True,\n",
    "                                   featurewise_std_normalization = True,width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,shear_range=0.25,zoom_range=0.1,\n",
    "                                   zca_whitening = True,channel_shift_range = 20,\n",
    "                                   horizontal_flip = True,vertical_flip = True,\n",
    "                                   validation_split = 0.2,fill_mode='constant')\n",
    "\n",
    "train_batches = train_datagen.flow_from_directory(DATASET_PATH,target_size=IMAGE_SIZE,\n",
    "                                                  shuffle=True,batch_size=BATCH_SIZE,\n",
    "                                                  subset = \"training\",seed=42,\n",
    "                                                  class_mode=\"binary\")\n",
    "\n",
    "valid_batches = train_datagen.flow_from_directory(DATASET_PATH,target_size=IMAGE_SIZE,\n",
    "                                                  shuffle=True,batch_size=BATCH_SIZE,\n",
    "                                                  subset = \"validation\",seed=42,\n",
    "                                                  class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### [10 points] Build Model\n",
    "Hint: Starting from a pre-trained model typically helps performance on a new task, e.g. starting with weights obtained by training on ImageNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "5c52eeb2-1092-4d45-9e16-02219c82cb5e"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 7, 7, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_feature (Dense)        (None, 256)               3211520   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_output (Dense)         (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 19,696,449\n",
      "Trainable params: 4,981,761\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#raise NotImplementedError(\"Build your model based on an architecture of your choice \"\n",
    "#                          \"A sample model summary is shown below\")\n",
    "\n",
    "# load pre-trained model; the defult input size is 224 x 224.  \n",
    "vgg16 = tf.keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(224, 224, 3)) \n",
    "vgg16.trainable = False\n",
    "conv_1 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='conv_1')\n",
    "conv_2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='conv_2')\n",
    "flatten_1 = tf.keras.layers.Flatten(name='flatten_1')\n",
    "dropout_1 = tf.keras.layers.Dropout(0.25, name='dropout_1')\n",
    "dense_feature = tf.keras.layers.Dense(256, activation='relu',name='dense_feature')\n",
    "dropout_2 = tf.keras.layers.Dropout(0.25, name='dropout_2')\n",
    "dense_output = tf.keras.layers.Dense(1, name = 'dense_output',activation='sigmoid')\n",
    "    \n",
    "model = tf.keras.Sequential([vgg16,conv_1, conv_2,\n",
    "                             flatten_1,dropout_1,dense_feature,dropout_2,dense_output])\n",
    "model.build(input_shape=(None, 224, 224, 3))\n",
    "model.summary()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### [5 points] Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "cdb90d24-6a23-4969-8138-f37e7050062d"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "3\n",
      "WARNING:tensorflow:From <ipython-input-5-78364024fd44>:21: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:739: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 10 steps, validate for 2 steps\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:739: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 78s 8s/step - loss: 1.3850 - accuracy: 0.4255 - val_loss: 0.6538 - val_accuracy: 0.4500\n",
      "Epoch 2/40\n",
      " 3/10 [========>.....................] - ETA: 23s - loss: 0.6336 - accuracy: 0.7083"
     ]
    }
   ],
   "source": [
    "# change the learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=LEARNING_RATE,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "#FIT MODEL\n",
    "print(len(train_batches))\n",
    "print(len(valid_batches))\n",
    "\n",
    "STEP_SIZE_TRAIN=train_batches.n//train_batches.batch_size\n",
    "STEP_SIZE_VALID=valid_batches.n//valid_batches.batch_size\n",
    "\n",
    "#raise NotImplementedError(\"Use the model.fit function to train your network\")\n",
    "history = model.fit_generator(generator=train_batches,epochs=NUM_EPOCHS, validation_data=valid_batches,\n",
    "                   steps_per_epoch=STEP_SIZE_TRAIN, validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### [5 points] Plot Accuracy and Loss During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ff342098-784a-4e20-ac34-b74ca8ebe839"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#raise NotImplementedError(\"Plot the accuracy and the loss during training\")\n",
    "plt.plot(history.history['accuracy'], label='Train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_acc')\n",
    "plt.xlabel('Accuracy over 40 Epochs')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train_loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Loss over 40 Epochs')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### Plot Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "eval_generator = test_datagen.flow_from_directory(TEST_DIR,target_size=IMAGE_SIZE,\n",
    "                                                  batch_size=1,shuffle=False,class_mode=\"binary\")\n",
    "eval_generator.reset()\n",
    "pred = model.predict_generator(eval_generator,18,verbose=1)\n",
    "#print(pred)\n",
    "for index, probability in enumerate(pred):\n",
    "    image_path = TEST_DIR + \"/\" +eval_generator.filenames[index]\n",
    "    image = mpimg.imread(image_path)\n",
    "    if image.ndim < 3:\n",
    "        image = np.reshape(image,(image.shape[0],image.shape[1],1))\n",
    "        image = np.concatenate([image, image, image], 2)\n",
    "#         print(image.shape)\n",
    "\n",
    "    pixels = np.array(image)\n",
    "    plt.imshow(pixels)\n",
    "    \n",
    "    print(eval_generator.filenames[index])\n",
    "    if probability > 0.5:\n",
    "        plt.title(\"%.2f\" % (probability[0]*100) + \"% Normal\")\n",
    "    else:\n",
    "        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% COVID19 Pneumonia\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_generator.labels)\n",
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "## [10 points] TSNE Plot\n",
    "t-Distributed Stochastic Neighbor Embedding (t-SNE) is a widely used technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. After training is complete, extract features from a specific deep layer of your choice, use t-SNE to reduce the dimensionality of your extracted features to 2 dimensions and plot the resulting 2D features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "intermediate_layer_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('dense_feature').output)\n",
    "#print(intermediate_layer_model.layers)\n",
    "\n",
    "tsne_data_generator = test_datagen.flow_from_directory(DATASET_PATH,target_size=IMAGE_SIZE,\n",
    "                                                  batch_size=1,shuffle=False,class_mode=\"binary\")\n",
    "\n",
    "#raise NotImplementedError(\"Extract features from the tsne_data_generator and fit a t-SNE model for the features,\"\n",
    "#                          \"and plot the resulting 2D features of the two classes.\")\n",
    "X = intermediate_layer_model.predict_generator(tsne_data_generator)\n",
    "tsne = TSNE(n_components=2,verbose=1, perplexity=30,n_iter=1000, learning_rate=200)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "tsne_x = X_tsne[:, 0]\n",
    "tsne_y = X_tsne[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tsne_data_generator.labels  # lots of 0 and 1\n",
    "\n",
    "name_dic = {0:'Covid 19', 1:'Normal'}\n",
    "color_dic = {0:'red', 1:'blue'}\n",
    "#print(labels)\n",
    "\n",
    "choose_0 = []\n",
    "choose_1 = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 0:\n",
    "        choose_0.append(i)\n",
    "    else:\n",
    "        choose_1.append(i)\n",
    "\n",
    "partial_tsne_x_0 = np.take(tsne_x, choose_0)\n",
    "partial_tsne_y_0 = np.take(tsne_y, choose_0)\n",
    "    \n",
    "plt.scatter(partial_tsne_x_0, partial_tsne_y_0, label=name_dic[0], color=color_dic[0], marker='o')\n",
    "\n",
    "partial_tsne_x_1 = np.take(tsne_x, choose_1)\n",
    "partial_tsne_y_1 = np.take(tsne_y, choose_1)\n",
    "    \n",
    "plt.scatter(partial_tsne_x_1, partial_tsne_y_1, label=name_dic[1], color=color_dic[1], marker='o')\n",
    "    \n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Task 2: COVID-19 vs Normal vs Tertiary Pneumonia (Bacterial and Viral) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "<!-- #### Renew Training Batch and Validation Batch -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "<!-- #### Renew Model -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
